# Key Concepts {-}

*THIS IS A DRAFT*

These are the key concepts from the *Primer*. You should apply them whenever you face a choice, and some data to help you make it. The world confronts us. Makes decisions we must.

**Quantity of Interest** is the number which you want to estimate. You will almost always calculate a posterior probability distribution for your Quantity of Interest since, in the real world, it is almost always impossible to determine your QoI precisely. Most problems involve more than one QoI.

**Predictive Models and Causal Models** are different because predictive models have only one outcome column. Causal models have more than one (potential) outcome column because we need more than one potential outcome in order to estimate a *causal effect*. The first step in a data science problem is to determine if your QoI requires a causal or a predictive model.

**Units**, **outcomes** and **covariates** are important parts of every data science model. Causal, but not predictive, models also include **treatments**, which are just covariates which we can manipulate. The QoI determines the units and outcomes for your model.

**Preceptor Table** is the smallest possible table of data with rows and columns such that, if there is no missing data, then it is easy to estimate the quantities of interest.

[**Potential Outcome**](https://www.econometrics-with-r.org/13-1-poceaie.html) is the outcome for an individual under a potential treatment.

**Causal Effect** is the difference between two potential outcomes.

[**Rubin Causal Model**](https://en.wikipedia.org/wiki/Rubin_causal_model) is an approach to the statistical analysis of cause and effect based on the framework of potential outcomes.

**Wisdom** is the first [Cardinal Virtue](https://en.wikipedia.org/wiki/Cardinal_virtues) in data science. Begin with the quantity of interest. Is that QoI a causal effect or simply a forecast? Which units and outcomes does it imply? What Preceptor Table would allow you to calculate your QoI easily? Perform an exploratory data analysis (EDA) on the data you have. Is it *valid* to consider the data you have and the (theoretical) data from the Preceptor Table to have arisen out of the same population? If so, you may continue. If not, your attempt to estimate your QoI ends now.

**Validity** is the consistency, or lack there of, in the columns of our dataset and the corresponding columns in your Preceptor Table. In order to consider the two datasets to be drawn from the same population, the columns from one must be have a valid correspondence with the columns in the other. Validity, if true (or at least reasonable), allows us to construct the Population Table.

**Population Table** can be constructed if the validity assumption is (mostly) true. It includes all the rows and columns from the Preceptor Table. It also includes the rows and columns from the data set. It generally has other rows as well, rows which represent unit/time combinations from other components of the population.

**Justice** is the second [Cardinal Virtue](https://en.wikipedia.org/wiki/Cardinal_virtues) in data science. Justice starts with the Population Table – the data we want to have, the data which we actually have, and all the other data from that same population. Each row of the Population Table is defined by a unique Unit/Time combination. We explore three key issues about the Population Table. First, does the relationship among the variables demonstrate stability, meaning is the model stable across different time periods? Second, are the rows associated with the data representative of all the units which we might have had data for from that time period? Third, for causal models only, we consider unconfoundedness. Justice concludes by making an assumption about the data generating mechanism. Which general mathematical formula connects the outcome variable we are interested in with the other data that we have?

**Stability** means that the relationship between the columns in the Population Table is the same for three categories of rows: the data, the Preceptor Table, and the larger population from which both are drawn.

**Representativeness**, or the lack thereof, concerns two relationship, among the rows in the Population Table. The first is between the Preceptor Table and the other rows. The second is between our data and the other rows. Ideally, we would like both the Preceptor Table *and* our data to be random samples from the population. Sadly, this is almost never the case.

**Unconfoundedness** means that the treatment assignment is independent of the potential outcomes, when we condition on pre-treatment covariates. This assumption is only relevant for causal models. We write that a model is "confounded" if this is not true. The easiest way to ensure unconfoundedness is to randonly assign treatment.

**Courage** is the third [Cardinal Virtue](https://en.wikipedia.org/wiki/Cardinal_virtues) in data science. Justice gave us the data and the structure of the model. Courage allows us to explore different models. Even though Justice has provided the basic mathematical structure of the model, we still need to decide which variables to include and to estimate the values of unknown parameters. We avoid hypothesis tests. We check our models for consistency with the data we have. We select one model.

**Temperance** is the fourth [Cardinal Virtue](https://en.wikipedia.org/wiki/Cardinal_virtues) in data science. Courage gave us the fitted model. Temperance guides us in the use of the model we have created to answer the questions we began with. We create posteriors of the quantities of interest. We should be modest in the claims we make. The posteriors we create are never the “truth.” The assumptions we made to create the model are never perfect. Yet decisions made with flawed posteriors are almost always better than decisions made without them.


## Steps to Take in Every Data Science Problem

In the spirit of transparency, here are the guidelines which we provide to co-authors updating chapters in the *Primer*. This is how we think data science ought to be taught. It is also, perhaps unsurprisingly, how we think data science ought to be done, at least at this introductory level.

### Question

Start with the question. This will generally be something simple, easily expressed in just a sentence, using colloquial language. Every data science problem starts with a question. The goal is to provide an answer to the question, along with your uncertainty about that answer. The most common form for the answer is a posterior probability distribution. This PPD is either the answer itself, or the tool we use to answer the question. Example:

"What proportion of people who make $100,000 are liberal?"

Of course, every data science problem does not start with a question. It actually starts with a decision. The world confronts us. Make decisions we must. Yet, in this introductory textbook, starting with a decision to make is too hard. So, we simplify and start with a question. But we should always at least mention the sort of decision which the answer to the question might help us to make.

Note that the sophistication of these discussions increases as we go further into the book. Your discussion should be more sophisticated than that found in the previous chapter and less sophisticated than what comes later. 

Each chapter features all the same sections and sub-sections as we use below. That is, there are three sub-sections to Wisdom, five sub-sections for Justice, and so on. 

Once we have our question, we can start with the Cardinal Virtues. Each section begins with a one sentence summary about the component steps of the relevant virtue. These will, obviously, be highly similar from chapter to chapter. But that is OK! We want to reinforce the steps in the path over and over again.

### Wisdom

"Wisdom requires the creation of a Preceptor Table, an examination of our data, and a determination, using the concept of validity, as to whether or not we can (reasonably!) assume that the two come from the same population."

#### Preceptor Table

The Preceptor Table always begins with a restatement of the definition: "A Preceptor Table is smallest possible table with rows and columns such that, if there is no missing data, our question is easy to answer."

To create the Preceptor Table, we answer a series of questions. (Don't ask these questions rhetorically. Just describe the answer. There is also no need to number them, although you should always use this order.)

* Is the question causal?  Looks for words like "cause" or "affect" or "influence." Look for a question which implies a comparison, *for a single individual unit*, between two states of the world, one where they get treatment X and one where they get treatment Y. Look for a discussion of something which we can *manipulate*. Remember the motto: *No causation without manipulation*. We look to see if the question seeks to compare two potential outcomes *within the same unit*, rather than the same outcome between two different units.

If none of this is present, use a predictive model. If all you need to know to answer the question is the outcome under one value of the treatment, then the model is predictive. Example: What is the att_end for all women if they were to get the treatment? This is a predictive question, not a causal one, because we do not need to know the outcome under treatment and under control for any individual woman.

* What is the moment in time to which the question refers? Every question refers to a moment in time, even if that moment stretches a bit. The set of adults *today* is different from the set 10 years ago, or even yesterday. We need to *refine* the origial question. Assume that we are referring to July 1, 2012. We have changed the original question from: 

"What proportion of people who make $100,000 are liberal?" 

to

"On July 1, 2012, what proportion of people who make $100,000 were liberal?"

* What are the units? The question often makes this fairly clear, at least in terms of what each row corresponds to, whether it be individuals, classrooms or countries. But, questions often fail to make clear the total number of the rows. Our example question above does not specify the relevant population. Is it about all the people in the world? All the adults? All the adults in the United States? The purpose of this paragraph is to *refine* the question, to make it more specific. Assume that we are interested in all the adults in Chicago. Our question now is:

"On July 1, 2012, what proportion of the adults in Chicago who make $100,000 were liberal?"

This back-and-forth between the question and the analysis is a standard part of data science. We rarely answer the exact question we started with, especially because that question is never specific enough to answer without further qualifications. Furthermore, the data we have may not allow us to answer that question, but it may be enough to answer a related question. Is that good enough for the boss/client/colleague who asked the original question? Maybe? We won't know till we ask. 

Our job as data scientists is not to simply answer the question we have been asked, but to help the questioner determine a question which can be answered with the data we have, a question which helps them to make the decision which they face.

* What are the outcomes? (If the model is causal, then there must be at least two potential outcomes. If you can't figure them out, then the model is probably predictive.) If the model is predictive, then there is only one outcome. This paragraph does more than just name the relevant variable. It also starts the discussion about how exactly we might measure this variable. We consider both underlying concept, "liberal," and the process by which we might operationalize the concept. Perhaps we are using a written survey with a YES/NO answer. Perhaps it is an in person interview with a 1-7 Likert scale, in which answers of 1 or 2 are coded, by us, as "liberal." The details don't matter, but we need to discuss.
 


What are the covariates? Discussing covariates in the context of the Preceptor Table is different than discussing covariates in the context of the data. Recall that the Preceptor Table is the smallest possible table, so we don't need to include every relevant variable. *We only need to discuss variables that are necessary to answer the question.* 

What are the treatments, if any? (There are no treatments in predictive models.) A treatment is a covariate which, at least in theory, we can manipulate and the manipulation of which is necessary to answer our question.

With all the above, create the Preceptor Table.

#### Validity

Validity discussions always have one (short) paragraph about each variable, with examples of why validity might *not* hold. Validity discussion finishes with a brief discussion along the lines of: "Despite these concerns, we will assume that validity does hold." 



### Justice

"Justice concerns five topics: the Population Table, stability, representativeness, unconfoundedness and the mathematical structure of the data generating mechanism (DGM)."

#### Population Table

#### Stability



#### Representativeness


And, of course, we always mention the two potential problems: Is our data representative of the population and is our Preceptor Table representative of the population? Each of these points gets its own short paragraph. There are always two levels of concerns: first is generic, second only applies to the variables you need to answer the question.

Representativeness is a concern for both the data and for the Preceptor Table. If you need data for an unrepresentative subset of the population, you might be in trouble. Or, you can try to adjust your question so that it is answerable for the data you have.

#### Unconfoundedness



### Courage

The opening Courage paragraph reminds us about Courage and also explains why we are using a linear (or logistic or whatever) model.

Series of fitted models, none of which are used to answer our question yet. Each time, we fit, print and the describe with math. Then, we explain it English what the model shows.

"Courage centers around the creation of the data generating mechanism, i.e., our fitted model."

Use gtsummary::tbl_regression() to show a nice table of the parameter values toward the end of the Courage section.

Courage section ends with a clear statement in English, in its own paragraph, describing the model. That is, what are the two sentence which a student would say at a presentation describing the model. First sentence specifies the model, including making clear the units, outcome and key covariates. (No need to use the terms "units," "outcomes," and so on.) The second sentence tells us about one key number, along with its associated uncertainty. With predictive models, the language almost always includes "When comparing two units (whatever those units are), one with covariate (whatever it is) value X and the other with value Y, the difference in outcome is . . . " With a causal model, you are almost always interested in the average causal effect (or treatment effect), although sometimes you provide this number for a particularly interesting/important subset of the data.

### Temperance

"Temperance guides us in the use of the DGM to answer the questions wit which we began."

